{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 1: Introduction to Machine Learning**\n",
        "**Applied Machine Learning**\\\n",
        "Machine Learning is the one of today's most exciting technologies.\\\n",
        "In this course, we will learn what machine learning is, what are the most important techniques in machine learning, and how to apply them to solve the problem in the real world."
      ],
      "metadata": {
        "id": "vzM95pj-Mdjf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 1: What is ML?**\n",
        "ML in everyday life:\n",
        "\n",
        "*   Search engines\n",
        "*   Personal Assistants: ML powers speech recognition, question answering and other intelligent capabilities of smartphone assistance like Apple Siri. \n",
        "\n",
        "*   Spam/Fraud detection\n",
        "*   Self-driving cars\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NsPRrqYDNSnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A Definition of Machine Learning**\\\n",
        "In 1959, Arthur Samel defined ML as follows:\n",
        "```\n",
        "Machine Learning is a field of study that gives computers the ability to learn \n",
        "without being explicitly programmed.\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zxqKZxPBOSnn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**An Example: Self Driving Car** \\\n",
        "A Self-Driving car system uses dozen of components that include detection of cars, padestrians, and other objects.\\\n",
        "**A Ruled-based algorithm:**\\\n",
        "One way to build a detection system is to write down the rules. In practices, it is almost impossible for human to specify all the edge cases.\\\n",
        "**An ML Approach**\\\n",
        "The ML approach is to teach a computer how to detection by showing it many examples of diffenrent objects. No manual programming is needed, the computer learns what defines a padestrian and a car on its own!\n"
      ],
      "metadata": {
        "id": "13HWNg9XPtOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Why Machine Learning?**\n",
        "Why is this approach to building software interesting?\n",
        "\n",
        "\n",
        "*   It allows building practical systems for the real-world application that couldn't be solved otherwise.\n",
        "*   Learning is widely regarded as a key approach towards building general-purpose artificail intelligent systems.\n",
        "\n",
        "\n",
        "*  The science and engineering of machine learning offers insights into humnan intelligence.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IKQbg9jzRmUe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Part 2: Three Approaches to Machine Learning**"
      ],
      "metadata": {
        "id": "L4KWrCh4S_Wu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine learning is broadly defined as the science of building software that has the ability to learn without being explitcitly programmed.\\\n",
        "**How might we enable machines to learn?**"
      ],
      "metadata": {
        "id": "y-bD7H3FTKr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Supervised Learning**\n",
        "The most common approach to machine learning is supervised learning:\n",
        "\n",
        "1.   First, we collect the dataset of labeled training examples. \n",
        "2.   We train the model to output accurate predictions on this dataset.\n",
        "3.   When the model see new, similar data, it will be also accurate.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kImYDvyCT1I9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 2: A supervised learning problem**"
      ],
      "metadata": {
        "id": "SGwjwswFZY-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **A supervised learning dataset**\n",
        "Consider a simple dataset for supervised learning: We will use the UCI Diabetes Dataset: it's a toy dataset that's often used to demonstrate machine learning algorithm.\n",
        "\n",
        "*   For each patient we have a access to a measurement of their body max index (BMI) and a quatitive diabetes risk score (from 0-400).\n",
        "*   We are interested in understading how BMI affects an individual's diabetes risk.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gLAHo-0MUqpt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "\n",
        "# Load the diabetes dataset\n",
        "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
        "\n",
        "# Use only the BMI feature\n",
        "diabetes_X = diabetes_X.loc[:, ['bmi']]\n",
        "\n",
        "# The BMI is zero-centered and normalized; we recenter it for ease of presentation\n",
        "diabetes_X = diabetes_X * 30 + 25\n",
        "\n",
        "# Collect 20 data points\n",
        "diabetes_X_train = diabetes_X.iloc[-20:]\n",
        "diabetes_y_train = diabetes_y.iloc[-20:]\n",
        "\n",
        "# Display some of the data points\n",
        "pd.concat([diabetes_X_train, diabetes_y_train], axis=1)"
      ],
      "metadata": {
        "id": "2Kvg7vMLf1VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also visualize this two-dimensionl dataset"
      ],
      "metadata": {
        "id": "pCRZvQw6aN9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [12,4]\n",
        "\n",
        "plt.scatter(diabetes_X_train, diabetes_y_train, color='red' )\n",
        "plt.xlabel('Body Mass Index (BMI)')\n",
        "plt.ylabel('Diabetes risk')"
      ],
      "metadata": {
        "id": "rPbnPaMGapSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **A Supervised Learning Algorithm (Part 1)**\n",
        "What is the relationship between BMI and diabetes risk? \\\n",
        "We could assume that risk is a linear function of BMI. In other words, for some unknown $\\theta_0, \\theta_1 \\in \\mathbb{R}$, we have:\n",
        "$$y = \\theta_1x + \\theta_0$$\n",
        "where $x$ is the BMI (also called the independent variable), $y$ is the diabetes risk (also called the dependent variable).\\\n",
        "Note that $\\theta_0, \\theta_1$ are the slope and intercept of the line relates $x$ to $y$. We call them *parameters*.\\\n",
        "We can visualize this for a few values of $\\theta_0, \\theta_1$.\n"
      ],
      "metadata": {
        "id": "5hJWVVGzcfRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "theta_list = [(1,2), (2,1), (1,0), (0,1)]\n",
        "for theta0, theta1 in theta_list:\n",
        "  x = np.arange(10)\n",
        "  y = theta1*x + theta0\n",
        "  plt.plot(x,y)"
      ],
      "metadata": {
        "id": "EShwTwg5aLtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **A Supervised Learning Algorithm (Part 2)**\n",
        "Assuming that $x,y$ follow the above relationship, the goal of the **supervised learning algorithm** is to find a good set of parameters consistent with the data. \\\n",
        "We will see many algorithms for this task. For now, let's call the `sklearn.liner_model` library to find a $\\theta_0, \\theta_1$ that fit the data well."
      ],
      "metadata": {
        "id": "pCrArzekfmhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(diabetes_X_train, diabetes_y_train.values )\n",
        "\n",
        "# Make prediction on the training set\n",
        "diabetes_y_train_pred = regr.predict(diabetes_X_train)\n",
        "\n",
        "# The coefficients\n",
        "print('Slope theta1: \\t', regr.coef_[0])\n",
        "print('Intercept theta2: \\t', regr.intercept_)"
      ],
      "metadata": {
        "id": "0AI9-eu_gsP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **A Supervised Learning Model** \n",
        "The supervised learning algorithm gave us a pair of $\\theta_0^*, \\theta_1^*$. These define the *predictive model* $f^*$, defined as:\n",
        "$$f(x) = \\theta_1^*x + \\theta_0^*$$\n",
        "where again $x$ is the BMI, and $y$ is the diabetes risk score.\\\n",
        "We can visualize the linear model that fits our data"
      ],
      "metadata": {
        "id": "rWzsDJT5XKHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Body Mass Index (BMI)')\n",
        "plt.ylabel('Diabetes risk')\n",
        "plt.scatter(diabetes_X_train, diabetes_y_train)\n",
        "plt.plot(diabetes_X_train, diabetes_y_train_pred, color='black', linewidth=2)"
      ],
      "metadata": {
        "id": "I1trXvAuezUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Predictions Using Supervised Learning**\n",
        "Given a new dataset of patients with a known BMI, we can use this model to estimate their diabetes risk.\\\n",
        "Given a new $x^{'}$, we can output a predicted $y^{'}$ as:\n",
        "$$y^{'} = f(x^{'}) = \\theta_1^{*}.x^{'} + \\theta_0^*$$\n",
        "Let's start by loading more data. We will load three new patients (shown in read below) that haven't seen before:"
      ],
      "metadata": {
        "id": "tK22kyw2aUmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect three new data points\n",
        "diabetes_X_test = diabetes_X.iloc[:3]\n",
        "diabetes_y_test = diabetes_y.iloc[:3]\n",
        "\n",
        "plt.scatter(diabetes_X_train, diabetes_y_train)\n",
        "plt.scatter(diabetes_X_test, diabetes_y_test, color='red')\n",
        "plt.xlabel('Body Mass Index (BMI)')\n",
        "plt.ylabel('Diabetes Risk')\n",
        "plt.legend(['Initial patients', 'New patients'])\n"
      ],
      "metadata": {
        "id": "9ooqMZrubYRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our linear model provides an estimate of the diabetes risk for these patients\n"
      ],
      "metadata": {
        "id": "pQu6ObVmdxgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate predictions on the new patients \n",
        "diabetes_y_test_pred = regr.predict(diabetes_X_test)  \n",
        "\n",
        "# Visualize the result \n",
        "plt.xlabel('Body Mass Index (BMI)')\n",
        "plt.ylabel('Diabetes Risk')\n",
        "plt.scatter(diabetes_X_train, diabetes_y_train)\n",
        "plt.scatter(diabetes_X_test, diabetes_y_test, color='red', marker='o')\n",
        "plt.plot(diabetes_X_train, diabetes_y_train_pred, color='black', linewidth=1)\n",
        "plt.plot(diabetes_X_test, diabetes_y_test_pred, 'x', color='red', mew=3, markersize=8)\n",
        "plt.legend(['Initial patients','New patients','Model', 'Predictions'])"
      ],
      "metadata": {
        "id": "_BFcYjOcdxH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Why Supervised Learning?**\n",
        "Supervised learning can be useful in many way:\n",
        "*   Making predictions on new data\n",
        "*   Understanding the mechanisms through which input variables affect targets.\n",
        "\n"
      ],
      "metadata": {
        "id": "7_8PLUdXkIdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Applications of Supervised learning**\n",
        "Many of the most important applications of machine learning are supervised learning:\n",
        "*   Classifying medical images,\n",
        "*   Translating between pairs of languages,\n",
        "*   Detecting objects in a self-driving car.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EiB_1dpmk4tj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 2: Anatomy of a Supervised Learning problem: Datasets**\n",
        "We have seen a simple example of a supervised learning prolem and an algorithm for solving this problem. \\\n",
        "Let's now look at what a general supervised learning prolem looks like "
      ],
      "metadata": {
        "id": "xgBC6U0onKlW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Recall: Three components of A Supervised Machine Learning Problem**\n",
        "At a high level, a supervised machine learning problem has following structure:\n",
        "$$Dataset + Algorithm \\rightarrow Predictive ~ Model$$\n",
        "The predictive model is chosen to model the relationships between inputs and targets. For instance, it can predict future targets."
      ],
      "metadata": {
        "id": "tYrQR4Eppgd5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **A Supervised Learning Dataset**\n",
        "\n",
        "We are going to dive deeper into what's a supervised learning dataset. As an example, consider the full version of the UCI Diabetes Dataset seem earlier.\\\n",
        "Previously, we only looked at the patients' BMI, but this dataset actually records many additional measurements.\\\n",
        "The UCI Diabetes contains many additional data columns besides `bmi`, including age, sex, and blood pressure. We can ask `sklearn` to give us more information about this dataset."
      ],
      "metadata": {
        "id": "OWRVbOg8qecO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [12,4]\n",
        "from sklearn import datasets\n",
        "\n",
        "# Load the diabetes dataset\n",
        "diabetes = datasets.load_diabetes(as_frame=True)\n",
        "print(diabetes.DESCR)"
      ],
      "metadata": {
        "id": "APndHq6GwR_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes"
      ],
      "metadata": {
        "id": "5b7dSOv60hr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **A Supervied Learning Dataset: Notation:**\n",
        "We say that a training dataset of size n (e.g., n patients) is a set:\n",
        "$$\\mathcal{D} = \\{(x^{(i)},y^{(i)}) | i= 1,2,...,n\\}$$\n",
        "Each $x^{(i)}$ denotes an input (e.g., the measurement for patient i), and each $y^{(i)} \\in \\mathcal{Y}$ is a target (e.g., the diabetes risk).\\\n",
        "Together, $(x^{(i)},y^{(i)})$ form a *training example*.\\\n",
        "We can look at the diabetes dataset in this form"
      ],
      "metadata": {
        "id": "DmeJuIy2xXB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the diabetes datasset\n",
        "diabetes_X, diabetes_y = diabetes.data, diabetes.target\n",
        "\n",
        "# Print part of the dataset\n",
        "diabetes_X.head()\n"
      ],
      "metadata": {
        "id": "oC7H4mvZz12j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training Dataset: Inputs**\n",
        "More precisely, an input $x^{(i)} \\in \\mathcal{X}$ is a $d$-dimensional vector of the form\n",
        "$$\\begin{align}\n",
        "    x^{(i)} &= \\begin{bmatrix}\n",
        "                x_1^{(i)} \\\\\n",
        "                x_2^{(i)} \\\\\n",
        "                \\vdots \\\\\n",
        "                x_d^{(i)}\n",
        "                \\end{bmatrix}\n",
        "  \\end{align}$$ \n",
        "\n",
        "For example, it could be the measurements the values of the $d$ features for the patient $i$.\\\n",
        "The set $\\mathcal{X}$ is called the feature space. Often, we have, $\\mathcal{X} = \\mathbb{R}^d$.\\\n",
        "Let's look at data for one patient:"
      ],
      "metadata": {
        "id": "NJyEswcu7H61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_X.iloc[0]"
      ],
      "metadata": {
        "id": "R4g6hfxl0epf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training Dataset: Attributes**\n",
        "We refer to the numerical variables describing the patient as attributes. Example of attributes include:\n",
        "\n",
        "*   The age of the patient,\n",
        "*   The patient's gender,\n",
        "*   The patient's BMI\n",
        "\n",
        "Note that these attributes in the above example have been mean-centered at zero and re-scaled to have a variance of one. "
      ],
      "metadata": {
        "id": "bv9-40NT-LXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training Dataset: Features**\n",
        "Often, an input object has many attributes, as we want to use these attributes to define more complex descriptions of the input  \n",
        "\n",
        "*   Is the patient old and a man? (Useful if old men are at risk)\n",
        "*   Is the BMI above the obesity threshold?\n",
        "\n",
        "We call these custom attributes *features*.\\\n",
        "Let's create an \"old man\" feature "
      ],
      "metadata": {
        "id": "QYBozbxX_292"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_X['old man'] = (diabetes_X['sex']>0) & (diabetes_X['age']>0.05)\n",
        "diabetes_X.head()"
      ],
      "metadata": {
        "id": "a-pp1BWj_2Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Training Dataset: Features**\n",
        "More formally, we can define a function $\\phi: \\mathcal{X} → \\mathbb{R}^p$ that takes an input $x^{(i)} \\in \\mathcal{X}$ and outputs $p$-dimensional vector\n",
        "$$\\begin{align}\n",
        "    \\phi(x^{(i)}) &= \\begin{bmatrix}\n",
        "                \\phi(x^{(i)})_1 \\\\\n",
        "                \\phi(x^{(i)})_2 \\\\\n",
        "                \\vdots \\\\\n",
        "                \\phi(x^{(i)})_p\n",
        "                \\end{bmatrix}\n",
        "  \\end{align}$$ \n",
        "\n",
        "We say that $\\phi(x^{(i)})$ is a featurized input, and each $\\phi(x^{(i)})_j$ is a *feature*."
      ],
      "metadata": {
        "id": "KGsEtWI-CyY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Features and Attributes**\n",
        "In practice, the terms attribute and feature are often used interchangeably. Most author refer to $x^{(i)}$ as a vector of features (i.e., they've have been precomputed).\\\n",
        "We will follow this convention and use attribute only when there is ambiguity between attribute and feature."
      ],
      "metadata": {
        "id": "blh6cguIFxhX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Feature: Discrete vs. Continuous**\n",
        "Features can be either discrete or continuous. We will see later that they may be handled differently by ML algorithms.\\\n",
        "The BMI feature that we have seen earlier is an example of continuous feature.\\\n",
        "We can visualise its distribution.\n"
      ],
      "metadata": {
        "id": "fY3w4Js1I4_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diabetes_X.loc[:,'bmi'].hist()"
      ],
      "metadata": {
        "id": "bseYZ__A-K6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other features take on one of a finite number of dicrete values. The `sex` column is an example of a categorical feature.\\\n",
        "In this example, the dataset has been pre-processed such that the two values happen to be `0.05068012` and `-0.04464164`."
      ],
      "metadata": {
        "id": "iTTT7nJ9KFyQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(diabetes_X.loc[:,'sex'].unique())\n",
        "diabetes_X.loc[:,'sex'].hist()"
      ],
      "metadata": {
        "id": "7_bUV69y-BZs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training Dataset: Targets**\n",
        "For each patient, we are interested in predicting a quantity of interest, the *target*. In our example, this is the patient's diabetes risk.\\\n",
        "Formally, when $(x^{(i)},y^{(i)})$ form a *training example*, each $y^{(i)} \\in \\mathcal{Y}$ is the target, and  $\\mathcal{Y}$ is the target space.\\\n",
        "We plot the distribution of risk scores below:"
      ],
      "metadata": {
        "id": "f3Pen0SVLLOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.xlabel('Diabetes risk')\n",
        "plt.ylabel('Number of patients')\n",
        "diabetes_y.hist()"
      ],
      "metadata": {
        "id": "u-JmeV1UK_zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Target: Regression vs. Classification**\n",
        "We distinguish between two broad types of supervised learning problems that differ in the form of the target variables.\n",
        "\n",
        "\n",
        "*   **Regression**:  The target variable $y$ is continuos. We are fitting a curve in a high-dimensional feature space that approximates the shape of the dataset.\n",
        "*   **Classification**: The target variable $y$ is discrete. Each discrete value corresponds to a classs and we are looking for a hyperplane that separates the different classes.\n",
        "\n",
        "We can easily turn our earlier regression example into classification by discretizing the diabetes risk scores into high or low\n",
        "\n"
      ],
      "metadata": {
        "id": "jlspnqeSM-x6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the diabetes dataset\n",
        "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True, as_frame=True)\n",
        "\n",
        "# Use only the BMI feature\n",
        "diabetes_X = diabetes_X.loc[:, ['bmi']]\n",
        "\n",
        "# The BMI is zero-centered and normalized; we recenter it for ease of presentation\n",
        "diabetes_X = diabetes_X * 30 + 25\n",
        "\n",
        "# Collect 20 data points\n",
        "diabetes_X_train = diabetes_X.iloc[-20:]\n",
        "diabetes_y_train = diabetes_y.iloc[-20:]\n",
        "\n",
        "# Display some of the data points\n",
        "pd.concat([diabetes_X_train, diabetes_y_train], axis=1)"
      ],
      "metadata": {
        "id": "4ANpPlNb0vfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Discretizing the target\n",
        "diabetes_y_train_discr = np.digitize(diabetes_y_train, bins=[150])\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(diabetes_X_train[diabetes_y_train_discr==0], diabetes_y_train[diabetes_y_train_discr==0],marker='o', s=80, facecolors='none', edgecolors='green')\n",
        "plt.scatter(diabetes_X_train[diabetes_y_train_discr==1], diabetes_y_train[diabetes_y_train_discr==1],marker='o', s=80, facecolors='none', edgecolors='red')\n",
        "plt.legend(['Low-Risk Patients','High-Risk Patients'])"
      ],
      "metadata": {
        "id": "YTqYgdCeMlNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's generate predictions for this dataset"
      ],
      "metadata": {
        "id": "MYdwsW3w5OG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# Create the Logistic regression object (note: this is actually classification algorithm!)\n",
        "clf = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using training sets\n",
        "clf.fit(diabetes_X_train, diabetes_y_train_discr)\n",
        "\n",
        "# Make predictions on the training set\n",
        "diabetes_y_train_pred = clf.predict(diabetes_X_train)\n",
        "\n",
        "# Visualize it\n",
        "plt.scatter(diabetes_X_train[diabetes_y_train_discr==0], diabetes_y_train[diabetes_y_train_discr==0], marker='o', s=140, facecolors='none', edgecolors='g')\n",
        "plt.scatter(diabetes_X_train[diabetes_y_train_discr==1], diabetes_y_train[diabetes_y_train_discr==1], marker='o', s=140, facecolors='none', edgecolors='r')\n",
        "plt.scatter(diabetes_X_train[diabetes_y_train_pred==0], diabetes_y_train[diabetes_y_train_pred==0], color='g', s=20)\n",
        "plt.scatter(diabetes_X_train[diabetes_y_train_pred==1], diabetes_y_train[diabetes_y_train_pred==1], color='r', s=20)\n",
        "plt.legend(['Low-Risk Patients', 'High-Risk Patients', 'Low-Risk Predictions', 'High-Risk Predictions'])"
      ],
      "metadata": {
        "id": "LxI7Omub5Sr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 3: Anatomy of a Supervised Learning Problem: Learning Algorithm**"
      ],
      "metadata": {
        "id": "cEMpWMQw1uZw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now look at what a general supervised learning algorithms looks like"
      ],
      "metadata": {
        "id": "fF8Ab2KJ3X0J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Recall: Three components of A Supervised Machine Learning Problem** \n",
        "At a high level, a supervised machine learning prolem has the following structure: \\\n",
        "$$Dataset + Algorithm → Predictive ~ Model$$\n",
        "The predictive model is chosen to model the relationship between inputs and targets. For instance, it can predict future targets."
      ],
      "metadata": {
        "id": "0Pdot4Sy3gMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **The Components of A Supervised Machine Learning Algorithm**\n",
        "We can also define the high-level structure of a supervised machine learning algorithm as consisting of three components: \n",
        "\n",
        "*   A **model class**: the set of possible models we consider\n",
        "*   An **objective function**, which defines how good a model is\n",
        "*   An **optimizer**, which finds the best predictive model in the model class according to the objective function.\n"
      ],
      "metadata": {
        "id": "hmtCdk4s8UBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at our diabetes dataset for an example:"
      ],
      "metadata": {
        "id": "Sy-cwMCC9rTY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['figure.figsize'] = [12,4]\n",
        "\n",
        "# Load the diabetes dataset\n",
        "diabetes = datasets.load_diabetes(as_frame=True)\n",
        "diabetes_X, diabetes_y = diabetes.data, diabetes.target\n",
        "\n",
        "# Print part of dataset\n",
        "diabetes_X.head()"
      ],
      "metadata": {
        "id": "-mR06TPovegj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model: Notation**\n",
        "We'll say that a model is a function \n",
        "$$f: \\mathcal{X} → \\mathcal{Y}$$\n",
        "that maps inputs $x \\in \\mathcal{X}$ to targets $y \\in \\mathcal{Y}$.\\\n",
        "Often, models have parameters $\\theta \\in Θ$. We will then write the model as:\n",
        "$$f_{\\theta}: \\mathcal{X} → \\mathcal{Y}$$\n",
        "to denote that it's parametrized by $θ$"
      ],
      "metadata": {
        "id": "Bs89C8bT-yfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Class: Notation**\n",
        "Formally, the model class is a set\n",
        "$$\\mathcal{M} \\subseteq \\{f \\mid f:\\mathcal{X} \\to \\mathcal{Y}\\}$$\n",
        "of possible models that map features to targets.\\\n",
        "When the model $f_{\\theta}$ is parametrized by $\\theta \\in \\Theta$. Thus we can write as:\n",
        "$$\\mathcal{M} = \\{f_{\\theta} \\mid f:\\mathcal{X} \\to \\mathcal{Y}; \\theta \\in \\Theta\\}.$$"
      ],
      "metadata": {
        "id": "CZN7LN8l_vZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model Class: Example**\n",
        "One simple example is to assume that x and y are related by a linear model of the form\n",
        "$$y = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\dots + \\theta_dx_d$$\n",
        "where x is feturized output and y is the target.\\\n",
        "The $\\theta_j$ are the *parameters* of the model."
      ],
      "metadata": {
        "id": "OQCTiH0GBTEp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Objectives: Notation**\n",
        "To capture this intuition, we define an objecctive function (also call a *loss function*)\n",
        "$$J(f) : \\mathcal{M} \\to [0,∞),$$\n",
        "\n",
        "which describes the extent to which f \"fits\" tha data $\\mathcal{D} = \\{(x^{(i)},y^{(i)}) \\mid i = 1,2, \\dots, n\\}$. \\\n",
        "\n",
        "When $f$ is parametrized by $\\theta \\in \\Theta$, the ojective becomes the function $J(\\theta): \\Theta \\to [0,∞). $\n"
      ],
      "metadata": {
        "id": "6IQU0jIHCfRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Objective: Example**\n",
        "What would if some possible objective functions? We will see many, but here aer a few example:\n",
        "\n",
        "\n",
        "*   Mean Squared Error:\n",
        "$$J(\\theta) = \\frac{1}{2n}\\sum_{i=1}^n(f_{\\theta}(x^{(i)}) - y^{(i)})^2$$\n",
        "*   Absolute (L1) Error:\n",
        "$$J(\\theta) = \\frac{1}{2}\\sum_{i=1}^n\\left|f_{\\theta}(x^{(i)}) - y^{(i)}\\right|$$\n",
        "\n",
        "These are defined for the dataset $\\mathcal{D} = \\{(x^{(i)},y^{(i)}) \\mid i = 1,2, \\dots, n\\}$.\n"
      ],
      "metadata": {
        "id": "lxiwToMzEaaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "\n",
        "y1 = np.array([1,2,3,4])\n",
        "y2 = np.array([-1,1,3,5])\n",
        "\n",
        "print('Mean Squared Error: %.2f' % mean_squared_error(y1,y2))\n",
        "print('Mean Absolute Error: %.2f' % mean_absolute_error(y1,y2))"
      ],
      "metadata": {
        "id": "vYox-22i-tBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Optimizer: Notation**\n",
        "At a high-level an optimizer takes an objective $J$ and a model class $\\mathcal{M}$ and finds a model $f \\in \\mathcal{M}$ with the smallest value of the objective $J$\n",
        "\n",
        "$$min_{f\\in\\mathcal{M}}J(f)$$\n",
        "\n",
        "intuitively, this is the function that bests \"fits\" the data on the training set. \\\n",
        "\n",
        "When $f$ is parametrized by $\\theta \\in \\Theta$, the optimizer mminimizes a function $J(\\theta)$ over all $\\theta \\in \\Theta$\n"
      ],
      "metadata": {
        "id": "VlTVvDqqG57t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Optimizer: Example**\n",
        "We will see that behind the scenes, the [sklearn.linear_models.LinearRegression]() algorithm optimize the MSE loss:\n",
        "$$min_{\\theta \\in \\mathbb{R}}\\frac{1}{2n}\\sum_{i=1}^n(f_{\\theta}(x^{(i)}) - y^{(i)})^2$$\n",
        "\n",
        "We can easily measure the quality of the fit on the training set and the test set. \\\n",
        "\n",
        "Lat's run the above algorithm on our diabetes dataset:"
      ],
      "metadata": {
        "id": "rWG4uz7aIhaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import linear_model\n",
        "# Collect 20 data points for training\n",
        "diabetes_X_train = diabetes_X.iloc[-20:]\n",
        "diabetes_y_train = diabetes_y.iloc[-20:]\n",
        "\n",
        "# Create a linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training set\n",
        "regr.fit(diabetes_X_train, diabetes_y_train.values)\n",
        "\n",
        "# Make prediction on the training set\n",
        "diabetes_y_train_pred = regr.predict(diabetes_X_train)\n",
        "\n",
        "# Collect three data points for testing\n",
        "diabetes_X_test = diabetes_X.iloc[:3]\n",
        "diabetes_y_test = diabetes_y.iloc[:3]\n",
        "\n",
        "# Generate prediction on the new patients \n",
        "diabetes_y_test_pred = regr.predict(diabetes_X_test)"
      ],
      "metadata": {
        "id": "IgBleiodJ2Yn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The algorithm returns a predictive. We can visualize its prediction below"
      ],
      "metadata": {
        "id": "s_kXwYRQM-F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize the result\n",
        "plt.xlabel('Body Mass Index (BMI)')\n",
        "plt.ylabel('Diabetes Risk')\n",
        "plt.scatter(diabetes_X_train.loc[:, ['bmi']], diabetes_y_train)\n",
        "plt.scatter(diabetes_X_test.loc[:, ['bmi']], diabetes_y_test, color='r', marker='o')\n",
        "plt.scatter(diabetes_X_train.loc[:, ['bmi']], diabetes_y_train_pred, color='y', linewidth=1)\n",
        "plt.plot(diabetes_X_test.loc[:, ['bmi']], diabetes_y_test_pred, 'x', color='r', mew=3, markersize=8)\n",
        "plt.legend([ 'Initial Patients', 'New Patients', 'Prediction', 'Model'])"
      ],
      "metadata": {
        "id": "1VAUu1fuNVxn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "print('Training set mean squared error: %.2f'\n",
        "      % mean_squared_error(diabetes_y_train, diabetes_y_train_pred))\n",
        "print('Test set mean squared error: %.2f'\n",
        "      % mean_squared_error(diabetes_y_test, diabetes_y_test_pred))\n",
        "print('Test set mean squared error on random inputs: %.2f'\n",
        "      % mean_squared_error(diabetes_y_test, np.random.randn(*diabetes_y_test_pred.shape)))"
      ],
      "metadata": {
        "id": "xUEkU765Opfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Summary: Components of A Supervised Machine Learning Problem**\n",
        "At a high-level, a supervised machine learning problem has the following structure:\n",
        "$$Dataset + \\underbrace{\\text{Algorithm}}_\\text{Model Class + Objective + Optimizer} \\to Predictive ~ Model$$\n",
        "\n",
        "The predictive model is chosen to model the relationship between the inputs and targets. For instance, it can predict future targets.\n"
      ],
      "metadata": {
        "id": "rlZARPy_fBH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Notation: Feature Matrix**\n",
        "Suppose that we have a dataset of size n (e.g., n patients), indexed by $i = 1,2, \\dots, n$. Each $x^{(i)}$ is a vetor of $d$ features.\n",
        "\n",
        "**Feature Matrix:**\n",
        "Machine Learning algorithms are most easily defined in the language of linear algebra. Therefore, it will be useful to preresent the entire dataset as one matrix $X \\in \\mathbb{R}^{n+d}$, of the form:\n",
        "$$X = \\begin{bmatrix}\n",
        "x^{(1)}_1 + x^{(2)}_1 + \\ldots + x^{(n)}_1\\\\\n",
        "x^{(1)}_2 + x^{(2)}_2 + \\ldots + x^{(n)}_2\\\\\n",
        "\\vdots \\\\\n",
        "x^{(1)}_d + x^{(2)}_d + \\ldots + x^{(n)}_d\\\\\n",
        "\\end{bmatrix}.$$\n",
        "Similarly, we can vectorize the target variables into a vector $y \\in \\mathbb{R}^n$ of the form:\n",
        "$$y = \\begin{bmatrix}\n",
        "x^{(1)} \\\\\n",
        "x^{(2)}\\\\\n",
        "\\vdots \\\\\n",
        "x^{(n)}\n",
        "\\end{bmatrix}.$$"
      ],
      "metadata": {
        "id": "DfbUlNJ7gW1q"
      }
    }
  ]
}