{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Lecture 5: Maximum Likelihood Learning**\n",
        "## **Applied Machine Learning**"
      ],
      "metadata": {
        "id": "5OPWsL_rz5CL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Why Does Supervised Learning Work?**\n",
        "Previously, we saw one way of explaining why supervised learning works."
      ],
      "metadata": {
        "id": "l96Fplw80IlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 1: Probabilistic Modeling**\n",
        "In this lecture, we are going to look at why supervised learning works from a new, probabilistic perspective. \\\n",
        "First, we are going to start by defining the probabilistic approach to machine learning and set up new notation."
      ],
      "metadata": {
        "id": "4HQF6Xve0mqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Review: Machine Learning Model**\n",
        "A machine learning model is a function\n",
        "$$f : \\mathcal{X} \\to \\mathcal{Y}$$\n",
        "that maps inputs $x \\in \\mathcal{X}$ to targets $y \\in \\mathcal{Y}$.\n",
        "Often, models have parameters $\\theta \\in \\Theta$. We will then write the model as:\n",
        "$$f_{\\theta}: \\mathcal{X} \\to \\mathcal{Y}$$\n",
        "to denote that it's parametrized by $\\theta$."
      ],
      "metadata": {
        "id": "Z5nVY2-v3LyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Review: Data Distribution**\n",
        "We will assume that the dataset is governed by a probability distribution $\\mathbb{P}$, which we will call the *data distribution*. We will denote this as:\n",
        "$$x,y \\sim \\mathbb{P}.$$\n",
        "The training set $\\mathcal{D} = \\{(x^{(i)},y^{(i)}) \\mid i = 1,2,\\dots,n\\}$ consists of independent and identically distributed (IID) samples from $\\mathbb{P}$.\n"
      ],
      "metadata": {
        "id": "CEF-f2wM3L7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Probabilistic Models**\n",
        "A Probabilistc model is a probability distribution\n",
        "$$P(x,y): \\mathcal{X} \\times \\mathcal{Y} \\to [0,1].$$\n",
        "This model can approximate the data distribution $P(x,y)$.\n",
        "Probabilistic models also have parameters $\\theta \\in \\Theta$, which we denote as:\n",
        "$$P_{\\theta}(x,y): \\mathcal{X} \\times \\mathcal{Y} \\to [0,1]. $$\n",
        "If we know $P_{\\theta}(x,y)$, we can use the conditional $P_{\\theta}(y \\mid x)$ for prediction."
      ],
      "metadata": {
        "id": "N0RK1ztd3MFP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Probabilistic Models: Example**\n",
        "Consider a simple version of our example with predicting diabetes from BMI.\n",
        "\n",
        "*   For the target $\\mathcal{Y} = {0, 1}$, we decretize the diasbetes risk score into low risk $(y = 0)$ and high risk $(y = 1)$.\n",
        "*   For the input $\\mathcal{X} = {0,1,2}$, we also decretize the BMI into low $(x=0)$, medium $(x=1)$ and high $(x=2)$.\n",
        "\n",
        "Then the following is a simple probabilistic model:\n",
        "\n"
      ],
      "metadata": {
        "id": "YD4tk8w-7B39"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqfqQ945yzo5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_model = pd.DataFrame.from_records([\n",
        "    ['low', 'low', 0.2], ['medium', 'low', 0.1], ['high', 'low', 0.2],\n",
        "    ['low', 'high', 0.05], ['medium', 'high', 0.1], ['high', 'high', 0.35]\n",
        "], columns= ['BMI $x$', 'Risk $y$', 'P'])\n",
        "df_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Under this model we can compute $P(y \\mid x) = P(x,y)/P(x)$ as follows:"
      ],
      "metadata": {
        "id": "M5JBnTn4_Ckj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_px = df_model.groupby('BMI $x$').sum().rename(columns = {'P':'Px'})\n",
        "df_conditional_model = df_model.merge(df_px,  on='BMI $x$')\n",
        "df_conditional_model['$P(y|x)$'] = df_conditional_model['P']/df_conditional_model['Px']\n",
        "df_conditional_model.iloc[:,[0,1,4]]"
      ],
      "metadata": {
        "id": "ADr9OESh-9rY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Why Use Probabilistic Model?**\n",
        "The probabilistic approach to machine leaarning is powerful\n",
        "\n",
        "*   We can fit models that capture predictive uncertainty.\n",
        "*   We can construct models in a more principled way by explicitly modeling the data distribution.\n",
        "*   It offers a new perspective on why supervised learning works.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GaLivifLCyZG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 2: Monte Carlo Estimation**\n",
        "Next, we are going to define Monte Carlo estimation, a mathematical tool that will be important in machine learning."
      ],
      "metadata": {
        "id": "ruMLf1WqpDvt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Notation: Random Variables**\n",
        "Suppose that we have a variable $x \\in \\mathcal{X}$ that is governed by a distribution $\\mathbb{P}$.\n",
        "$$x \\sim \\mathbb{P}(x).$$\n",
        "This $x$ can be sampled from data distribution, or any other random variable."
      ],
      "metadata": {
        "id": "-KAp6fXjphWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Notation: Expected Value**\n",
        "Recall that the expected value of a function $g: \\mathcal{X} \\to \\mathbb{R}$ when the input $x$ to $g$ is sampled from $\\mathbb{P}$ is given by\n",
        "$$\\mathbb{E}_{x \\sim \\mathbb{P}}[g(x)] = \\sum_{x}g(x)P(x),$$\n",
        "where we assumed for simplicity that $x$ is dicrete.\n",
        "\n",
        "In practice computing expected value is not always easy:\n",
        "\n",
        "*   $x$ can take on a very large number of values and summing over all of them is not possible.\n",
        "*   When $x$ is continuous, the expected value can be an integral with no closed form solution.\n",
        "\n",
        "In practice, we often use *approximate* methods to compute expected values.\n",
        "\n"
      ],
      "metadata": {
        "id": "itGIxigDphnZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Monte Carlo Estimation**\n",
        "Monte Carlo Estimation is a way to approximately compute expected values.\n",
        "$$\\mathbb{E}_{x \\sim \\mathbb{P}}[g(x)] = \\sum_{x}g(x)P(x),$$\n",
        "\n",
        "\n",
        "1.   We first generate $T$ IID samples $x_1, x_2, \\dots, x_T$ from $\\mathbb{P}$\n",
        "2.   Then we estimate the expected value as:\n",
        "$$\\hat{g}(x_1, x_2, \\dots, x_T) ≜ \\frac{1}{T}\\sum_{t=1}^Tg(x_t)$$\n",
        "\n",
        "We call $\\hat{g}$ is the Monte Carlo Estimation of the expected value.\n",
        "\n"
      ],
      "metadata": {
        "id": "ulAHTgxPphyw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Monte Carlo Estimation: Example**\n",
        "Let's say that we throw five dice. What is the expected number of twos?\n",
        "\n",
        "\n",
        "*   Let's $x = (x_1, x_2, \\dots,x_5)$ be a dice roll where $x_j \\in \\{1,2,\\dots,6\\}$ is the outcome of the $j$-th dice.\n",
        "*   Let $g(x)$ denote the number of twos in the roll of dice $x$.\n",
        "\n",
        "The expected value $\\mathbb{E}_{x \\sim \\mathbb{P}}[g(x)] = \\sum_{x}g(x)P(x)$ is the expected number of twos. We can calculate it as follows \n"
      ],
      "metadata": {
        "id": "TZizBN9AuPko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# sample 10,000 rolls of five dice\n",
        "dice_rolls = np.random.randint(0,6,size=(5,10000))\n",
        "\n",
        "# Count the number of twos in each throw\n",
        "TWO_VAL = 1 # twos are denoted by 1 because of zero-based indexing\n",
        "num_twos = (dice_rolls == TWO_VAL).sum(axis=0).mean()\n",
        "\n",
        "print('Monte Carlo Estimate: %.4f'% num_twos)"
      ],
      "metadata": {
        "id": "0IIEdyUQCn3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This makes scene, because the correct answer is $5/6 \\approx 0.83$"
      ],
      "metadata": {
        "id": "YRLxZDiuxfQY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Properties of Monte Carlo Estimaation**\n",
        "The Monte Carlo Estimation $\\hat{g}$ has the following properties:\n",
        "\n",
        "*   It is an unbiased estimate of the true expectation:\n",
        "$$\\mathbb{E}_P[\\hat{g}] = \\mathbb{E}_P[g(x)]$$\n",
        "*   It converges to the true expectation as we average the additional samples\n",
        "$$\\hat{g} = \\frac{1}{T}\\sum_{t=1}^Tg(x_t) \\rightarrow \\mathbb{E}_P[g(x)] \\text{ for } T → \\infty $$\n",
        "*   Ita variance decrese to zero as we collect more samples:\n",
        "$$\\text{var}_P(\\hat{g}) = \\text{var}_P\\left[\\frac{1}{T}\\sum_{t=1}^Tg(x_t)\\right] = \\frac{\\text{var}_P[g(x)]}{T}$$\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-Gc8KZDSx2BQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Monte Carlo: Summary**\n",
        "\n",
        "*   A lot of problems in Machine Learning require computing intractable expected values.\n",
        "*   Monte Carlo Estimation is a simple approximate method that compute expected values approximately.\n",
        "\n"
      ],
      "metadata": {
        "id": "oFjAqK4s0Nh8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 3: Maximum Likelihood**\n",
        "Maximum likelihood learning is a general way of training machine learning model. Many algorithms we have seen so far implicitly use this principle."
      ],
      "metadata": {
        "id": "yL3RQcPw0_1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Review: Data Distribution**\n",
        "We will assume that the dataset is governed by a probability distribution $\\mathbb{P}$, which we will call the *data distribution*. We will denote this as:\n",
        "$$x, y \\sim \\mathbb{P}.$$\n",
        "\n",
        "The training set $\\mathcal{D} = \\{(x^{(i)}, y^{(i)}) \\mid i=1,2,\\dots,n\\}$ consists of independent and identically distributed (IID) samples from $\\mathbb{P}$.\n"
      ],
      "metadata": {
        "id": "BqW7QuKH2s-i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Review: Probabilistic Model**\n",
        "A probabilistic model is a probability distribution\n",
        "$$P(x,y) : \\mathcal{X} \\times \\mathcal{Y} \\to [0,1]$$\n",
        "This model can appoximate the data distribution $\\mathbb{P}(x,y)$\n",
        "Probabilistic model can also have parameters $\\theta \\in \\Theta$, which we denote as\n",
        "$$P_{\\theta}(x,y) : \\mathcal{X} \\times \\mathcal{Y} \\to [0,1]$$\n",
        "\n",
        "If we know $P(x,y)$, we can use the conditional $P(y\\mid x)$ for prediction."
      ],
      "metadata": {
        "id": "4LDtdidA3jCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Learning Probabilistc Models**\n",
        "We now have a probabilistic model and a data distribution. Thus, it is natural to try to learn a good probability distribution $P_{\\theta}(x,y)$ that approximate the data distribution $\\mathbb{P}(x,y)$.\n",
        "What are characteristics of a good model $P_{\\theta}(x,y)$?\n",
        "\n",
        "\n",
        "*   **Predictive accuracy**: corretly predicting targets $y$ from $x$.\n",
        " *   Dose this patient have diabetes or not? \n",
        "*   **Understanding the relationships between $x$ and $y$**.\n",
        " *   What physicological features of the patient influence their diabetes risk?\n",
        "*   **Density estimation**: appoximating $\\mathbb{P}(x,y)$ so that we can answer any query later.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sP7MTAf-4qKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Kullback-Leibler Divergence**\n",
        "In order to appoximate $\\mathbb{P}$ with $P_{\\theta}$, we need a measure of distance between distributions.\n",
        "\n",
        "A standard measure of similarity between distribtions is Kullback-Leibler (KL) divergence between two distributions $p$ and $q$, defined as\n",
        "$$D(p \\| q) = \\sum_xp(x) \\log \\frac{p(x)}{q(x)}.$$\n",
        "\n",
        "Observations:\n",
        "\n",
        "\n",
        "*   $D(p \\| q) \\geq 0$ for all $p,q$, with equality if and only if $p = q$. Proof:\n",
        "$$\\begin{align*}\n",
        "D(p \\| q) = \\mathbb{E}_{x \\sim p} - \\log \\frac{q(x)}{p(x)} & \\geq -\\log\\left(\\mathbb{E}_{x \\sim p} \\frac{q(x)}{p(x)}\\right)\\\\\n",
        "&= - \\log\\left(\\sum_xp(x)\\frac{q(x)}{p(x)}\\right) \\\\\n",
        "&= 0\n",
        "\\end{align*}$$\n",
        "*   The KL-divergence is asymmetric, i.e., $D(p\\|q) \\neq D(q \\| p)$\n",
        "*   It has root in information theory.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "adC8uZ4-3jXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Learning models using KL-Divergence**\n",
        "We may now learn a probabilistic model $P_{\\theta}(x,y)$ that approximates the data distribution $\\mathbb{P}(x,y)$ via the KL-divergence:\n",
        "$$\\begin{align*}\n",
        "D(\\mathbb{P} \\| P_{\\theta}) &= \\mathbb{E}_{x,y \\sim \\mathbb{P}}\\log \\frac{\\mathbb{P}(x,y)}{P_{\\theta}(x,y)}\\\\\n",
        "&= \\sum_{x,y}\\mathbb{P}(x,y) \\log \\frac{\\mathbb{P}(x,y)}{P_{\\theta}(x,y)}\n",
        "\\end{align*}$$\n",
        "Note that $D(\\mathbb{P} \\| P_{\\theta}) = 0$ if the two distributions are the same."
      ],
      "metadata": {
        "id": "rSdUceo8-F67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **From KL Divergence to Log Likelihood**\n",
        "We can simplify the KL divergence objective somewhat:\n",
        "\n",
        "$$\\begin{align*}\n",
        "D(\\mathbb{P} \\| P_{\\theta}) &= \\mathbb{E}_{x,y \\sim \\mathbb{P}}\\log \\frac{\\mathbb{P}(x,y)}{P_{\\theta}(x,y)}\\\\\n",
        "&= \\mathbb{E}_{x,y \\sim \\mathbb{P}}\\log\\mathbb{P}(x,y) - \\mathbb{E}_{x,y \\sim \\mathbb{P}}\\log P_{\\theta}(x,y)\n",
        "\\end{align*}$$\n",
        "\n",
        "The first term does not depend on $P_{\\theta}$: minimize the Kl divergence is equal to maximize the expected log-likelihood.\n",
        "$$\\begin{align*}\n",
        "\\arg \\min_{P_{\\theta}} D(\\mathbb{P} \\| P_{\\theta}) &= \\arg\\min_{P_{\\theta}} - \\mathbb{E}_{x,y \\sim \\mathbb{P}} \\log P_{\\theta}(x,y)\\\\\n",
        "&= \\arg\\max_{P_{\\theta}} \\mathbb{E}_{x,y \\sim \\mathbb{P}} \\log P_{\\theta}(x,y).\n",
        "\\end{align*}$$\n",
        "\n",
        "We have now defined a learning objective equivalent to optimize the KL divergence\n",
        "$$\\arg\\max_{P_{\\theta}} \\mathbb{E}_{x,y \\sim \\mathbb{P}} \\log P_{\\theta}(x,y)$$\n",
        "\n",
        "\n",
        "*   This asks that $P_{\\theta}$ assign high probability to instances sampled from $\\mathbb{P}$, so as to reflect the true distribution.\n",
        "*   Because of $\\log$, samples $x, y$ where $P_{\\theta}(x,y) ≈ 0$ weigh heavily oin the objective \n",
        "\n",
        "Problem: In practice, we don't know the data distribution $\\mathbb{P}$, hence expected value is intractable."
      ],
      "metadata": {
        "id": "R4QHk3uX_2PK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Maximum Likelihood Estimation**\n",
        "Applying, Monte Carlo estimation, we may approximate the expected log-likelihood\n",
        "$$\\mathbb{E}_{x,y \\sim \\mathbb{P}}\\log P_{\\theta}(x,y) $$\n",
        "\n",
        "with the *empirical log-likelihoood*:\n",
        "$$\\mathbb{E}_{\\mathcal{D} \\sim P_{\\theta}(x,y)} = \\frac{1}{|\\mathcal{D}|}\\sum_{x,y \\in \\mathcal{D}}\\log P_{\\theta}(x,y)$$\n",
        "\n",
        "Maximum Likelihood Learning is then:\n",
        "$$\\max_{P_{\\theta}} \\frac{1}{|\\mathcal{D}|}\\sum_{x,y \\in \\mathcal{D}}\\log P_{\\theta}(x,y)$$"
      ],
      "metadata": {
        "id": "yn7Z1W5iKrEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example: Flipping a Random Coin**\n",
        "Consider a simple example in which we repeatedly toss a biased coin and record the outcomes.\n",
        "\n",
        "\n",
        "*   There are two possible outcomes: head ($H$) and tail ($T$). A training dataset consists of tosses of the biased coin, e.g., $\\mathcal{D} = \\{H, H, T, H, T \\}$.\n",
        "*   Assumption: true probability distribution is $\\mathbb{P}(x), x \\in \\{H,T\\}$\n",
        "*   Our task is to model the probability of heads/tails. Our class of models $\\mathcal{M}$ are Bernoulli distribution over $x \\in \\{H,T\\}$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G2EFt54kMvwu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example: Flipping a Random Coin (2)**\n",
        "How should we choose $P_{\\theta}$ from $\\mathcal{M}$ if $3$ out of $5$ tosses are heads in $\\mathcal{D}$? Let's apply maximum likelihood learning.\n",
        "\n",
        "*   Our model is $P_{\\theta}(x = H) = \\theta$ and $P_{\\theta}(x = T) = 1 - \\theta$.\n",
        "*   Our dataset is $\\mathcal{D} = \\{H, H, T, H, T \\}$.\n",
        "*   The likelihood of the data is $\\prod_iP_{\\theta}(x_i) = \\theta \\cdot \\theta \\cdot (1 - \\theta) \\cdot \\theta \\cdot (1 - \\theta)$.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9KVzm0FhOUrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We optimizes for $\\theta$ which makes $\\mathcal{D}$ most likely. what is the solution in this case? "
      ],
      "metadata": {
        "id": "e0Pr-pL1Pfb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Our dataset is {H,H,T,H,T}; if theta = P(x = H), we get:\n",
        "coin_likelihood = lambda theta: theta*theta*(1-theta)*theta*(1-theta)\n",
        "\n",
        "theta_vals = np.linspace(0,1)\n",
        "plt.plot(theta_vals, coin_likelihood(theta_vals))"
      ],
      "metadata": {
        "id": "TcdUS9SoPuZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example: Flipping a Random Coin (3)**\n",
        "Our Log-Likelihood function is\n",
        "$$\\begin{align*}\n",
        "L(\\theta) &= \\theta^{\\#\\,\\text{heads}}(1 - \\theta)^{\\#\\,\\text{tails}}\\\\\n",
        "\\log L(\\theta) &= \\log (\\theta^{\\#\\,\\text{heads}}(1 - \\theta)^{\\#\\,\\text{tails}})\\\\\n",
        "&= \\#\\,\\text{heads}\\cdot \\log (\\theta) + \\#\\,\\text{tails}\\cdot \\log (1 - \\theta)\n",
        "\\end{align*}$$\n",
        "\n",
        "the MLE estimate is the $\\theta^* \\in [0,1]$ such that $\\log L(\\theta^*)$ maximum.\n",
        "\n",
        "Differentiating the log-likelihood function with respect to $\\theta$ and set derivative to zero, we obtain.\n",
        "$$\\theta^* = \\frac{\\#\\, \\text{heads}}{\\#\\, \\text{heads} + \\#\\, \\text{tails}}$$\n",
        "\n",
        "When exact solutions are not available, we can optimize the log-likelihood numerically, e.g., using gradient descent.\n",
        "\n",
        "We will see examples of this later.\n"
      ],
      "metadata": {
        "id": "LetkkzJm-2rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conditional Maximum Likelihood**\n",
        "Sometimes, we may be interested in only fitting a *conditional* model $P(y \\mid x)$. For example, we may be only interested in predicting $y$ from $x$ rather than learning the joint structure of $x, y$.\n",
        "\n",
        "We can extend the principle of maximum likelihood learning to this setting as well. In this case, we are interested in minimizing:\n",
        "$$\\min_{\\theta}\\mathbb{E}_{x \\sim \\mathbb{P}}[D(\\mathbb{P}(y \\mid x) \\| P_{\\theta}(y \\mid x))],$$\n",
        "the expected KL divergence between $\\mathbb{P}(y \\mid x)$ and $P_{\\theta}(y \\mid x)$ over all the inputs $x$.\n",
        "\n",
        "With a bit of math, we can show that the maximum likelihood objective becomes\n",
        "$$\\max_{\\theta}\\mathbb{E}_{x,y \\sim \\mathbb{P}}\\log P_{\\theta}(y \\mid x)$$\n",
        "This is the principle of *conditional maximum likelihood*."
      ],
      "metadata": {
        "id": "rZnnvVgeBwVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 4: Extensions of Maximum Likelihood** \n",
        "Maximum Likelihood Learning is one approach for training probabilistic machine learning models.\\\n",
        "An even more general approach comes from Bayesian statistics. We briefly overview the Bayesian approach in this lesson."
      ],
      "metadata": {
        "id": "Oa-i8vQUEp9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Review: Maximum Likelihood Learning**\n",
        "Recall that in maximum likelihood learning, we are optimizing the following objective:\n",
        "$$\\theta_{MLE} = \\arg\\max_{\\theta}\\mathbb{E}_{x, y \\sim \\mathbb{P}}\\log P(y,x; \\theta).$$"
      ],
      "metadata": {
        "id": "jvHb-jx6AQMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **The Frequentist Approach** \n",
        "So far, we viewed the parameters $\\theta_{MLE}$ as a fixed but unknown quantity that we want to determine.\n",
        "$$\\theta_{MLE} = \\arg\\max_{\\theta}\\mathbb{E}_{x, y \\sim \\mathbb{P}}\\log P(y,x; \\theta).$$\n",
        "This view is an example of the *frequentist* approach in statistics, there exists some true values of $\\theta_{MLE}$ and our job is to devise statistical procedure to estimate this value. "
      ],
      "metadata": {
        "id": "if2dYdC2BiRs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **The Bayesian Approach**\n",
        "In Bayesian statistics, $\\theta$ is a random variable whose value happens to be unknown.\n",
        "\n",
        "We formulate two models:\n",
        "\n",
        "\n",
        "*   A likelihood model $P(x,y \\mid \\theta)$ that defines the probability of $x, y$ for any fixed value of $\\theta$.\n",
        "*   A prior $P(\\theta)$ that specifies us existing belief about the distribution of the random variable $\\theta$\n",
        "\n",
        "Together, these two models define the *joint distribution* \n",
        "$$P(x, y, \\theta) = P(x,y \\mid \\theta)P(\\theta)$$\n",
        "\n",
        "in which both the $x, y$ and the parameters $\\theta$ are random variables\n",
        "\n"
      ],
      "metadata": {
        "id": "U6uW-z4yCrGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bayesian Inference and Learning**\n",
        "How do we estimate the parameter $\\theta$ that is consistent with a given dataset $\\mathcal{D} = \\{(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \\cdots, (x^{(n)}, y^{(n)})\\}?$\n",
        "\n",
        "Since the variable $\\theta$ is an unknown random value, in Bayesian approach we are interested in the *posterior probability* $P(\\theta \\mid \\mathcal{D})$ of $\\theta$ given the dataset $\\mathcal{D}$.\n",
        "\n",
        "How do we obtain $P(\\theta \\mid \\mathcal{D})$? This value is computed using Bayes' rule:\n",
        "$$\\begin{align*}\n",
        "P(\\theta \\mid \\mathcal{D}) &= \\frac{P(\\mathcal{D} \\mid \\theta)P(\\theta)}{P(\\mathcal{D})} \\\\\n",
        "&= \\frac{P(\\mathcal{D} \\mid \\theta)P(\\theta)}{\\int_{\\theta}P(\\mathcal{D},\\theta)P(\\theta)d\\theta},\n",
        "\\end{align*}$$\n",
        "\n",
        "where $P(\\mathcal{D} \\mid \\theta) = \\prod_{i=1}^nP(x^{(i)}, y^{(i)} \\mid \\theta)$."
      ],
      "metadata": {
        "id": "WzQkErr6Edn7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Bayesian Predictions**\n",
        "Suppose we now want the predict the value $y$ from $x$. Unlike in the frequentist setting, we no longer have a single estimate $\\theta$ of the model params, instead we have a distribution.\n",
        "\n",
        "The Bayesian approach to predicting $y$ given an input $x$ and training set $\\mathcal{D}$ consists of taking the prediction of all the possible models\n",
        "$$P(y \\mid x, \\mathcal{D}) = \\int_{\\theta}P(y \\mid x, \\theta)P(\\theta \\mid \\mathcal{D})d\\theta.$$\n",
        "\n",
        "This is called the *posterior predictive* distribution. Note how each $P(y \\mid x, \\theta)$ is weighted by the probability of $\\theta$ given $\\mathcal{D}$"
      ],
      "metadata": {
        "id": "34O0zYexHQXV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **The Pros and Cons of the Bayesian Approach**\n",
        "The Bayesian is very powerful. Some of its advantages include:\n",
        "\n",
        "*   Principled estimates of uncertainty, both in the predictions and the parameters of the model\n",
        "*  Ability to incorporate prior knowledge via the prior\n",
        "*   Providing a general framework for reasoning about probabilistic model.\n",
        "\n",
        "The disadvantages is by far the computational complexity. Averaging over all possible weights is typically intractable. There exists an entire field of machine learning that learn how to appoximate it\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tQ0qUlmOJYcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Maximum A Posterior Learning**\n",
        "Instead of trying to use the *posterior distribution* of $P(\\theta \\mid \\mathcal{D})$, a common approach is to approximate this distribution by its most likely value:\n",
        "$$\\begin{align*}\n",
        "\\theta_{MAP} &= \\arg \\max_{\\theta} \\log P(\\theta \\mid \\mathcal{D}) \\\\\n",
        "&= \\arg \\max_{\\theta}(\\log P(\\mathcal{D} \\mid \\theta) + \\log P(\\theta) - \\log P(\\mathcal{D})) \\\\\n",
        "&= \\arg \\max_{\\theta} (\\log \\prod_{i=1}^nP(x^{(i)},y^{(i)} \\mid \\theta) + \\log P(\\theta)),\n",
        "\\end{align*}$$\n",
        "\n",
        "where in the second line we use the Bayesian theorem and in the third line we used the fact that $P(\\mathcal{D})$ does not depend on $\\theta$.\n",
        "\n",
        "Thus, we have the following objective:\n",
        "$$\\arg \\max_{\\theta} (\\log \\prod_{i=1}^nP(x^{(i)},y^{(i)} \\mid \\theta) + \\log P(\\theta))$$\n",
        "\n",
        "The $\\theta_{MAP}$ is known as the *maximum a posterior* estimate. Note that we use the same formula as we used for maximum likelihood, except that we have added the prior term $\\log P(\\theta)$."
      ],
      "metadata": {
        "id": "cIpQfdwQLF1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Example: Flipping a Random Coin**\n",
        "How should we choose $P(x \\mid \\theta)$ from $\\mathcal{M}$ if 3 out of 5 tosses are heads in $\\mathcal{D}$? Let's apply maximum likelihood learning.\n",
        "\n",
        "\n",
        "1.   Our Model is: $P(x = H \\mid \\theta) = \\theta$ and $P(x = T \\mid \\theta) = 1 -\\theta$\n",
        "2.   Our data is: $\\mathcal{D} = \\{H, H, T, H, T\\}$\n",
        "3. The likelihood of the data is $\\prod_iP(x_i | \\theta) = \\theta \\cdot \\theta \\cdot (1 - \\theta) \\cdot \\theta \\cdot (1 - \\theta).$\n",
        "\n",
        "Let's now make this a MAP problem. Let's assume the prior follows the [Beta]() distribution\n",
        "$$P(\\theta) = \\frac{1}{B(\\alpha + 1,\\beta + 1)}\\theta^{\\alpha}(1 - \\theta)^{𝛽},$$\n",
        "\n",
        "where $\\alpha, \\beta >0$ are parameters and $B$ is the [Beta] distribution.\n",
        "\n",
        "The joint probability on $\\mathcal{D} = \\{H, H, T, H, T\\}$ is then \n",
        "$$\\prod_iP(x_i | \\theta)P(\\theta) = \\theta \\cdot \\theta \\cdot (1 - \\theta) \\cdot \\theta \\cdot (1 - \\theta)\\frac{\\theta^{\\alpha}(1 - \\theta)^{𝛽}}{B(\\alpha + 1,\\beta + 1)}$$\n",
        "\n",
        "Let's derive an analytic solution. Our objective function is:\n",
        "$$\\begin{align*}\n",
        "L(\\theta) &\\propto \\theta^{\\#\\,\\text{heads}} \\cdot (1 - \\theta)^{\\#\\, \\text{tails}} \\cdot \\theta^{\\alpha} \\cdot (1 - \\theta)^{𝛽} \\\\\n",
        "\\log L(\\theta) &= \\log (\\theta^{\\#\\,\\text{heads}} \\cdot (1 - \\theta)^{\\#\\, \\text{tails}} \\cdot \\theta^{\\alpha} \\cdot (1 - \\theta)^{𝛽}) + \\text{const.} \\\\\n",
        "&= (\\#\\, \\text{heads} + \\alpha) \\log(\\theta) + (\\#\\, \\text{tails} + \\beta) \\log(1 - \\theta).\n",
        "\\end{align*}$$\n",
        "\n",
        "Differentiating the log-likelihood with respect to $\\theta$ and setting the derivative to zero, we obtain\n",
        "$$\\theta^* = \\frac{\\#\\, \\text{heads} + \\alpha}{\\#\\, \\text{heads} + \\#\\, \\text{tails} + \\alpha + \\beta}$$\n",
        "\n",
        "Thus we see that adding a Beta prior with parameters $\\alpha, \\beta$ allows to encode having seen $\\alpha$ (virtual heads) and $\\beta$ (virtual tails).\n",
        "\n",
        "For example, if our initial dataset is \n",
        "$$\\mathcal{D} = \\{H, H, T, H, T\\}$$\n",
        "and we set $\\alpha =1, \\beta = 1$, then the optimal $\\theta^*$ will be as if we had the following dataset\n",
        "$$\\mathcal{D}_{\\text{virtual}} = \\{H, H, T, H, T, H, T\\}$$\n",
        "with an extra heads and tails.\n"
      ],
      "metadata": {
        "id": "b6YTuKnWOjKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Our dataset is D={H,H,T,H,T}; if theta = P(x=H), we get\n",
        "alpha, beta = 1, 1\n",
        "# Our effective dataset is D={H,H,T,H,T,H,T}\n",
        "coin_likelihood = lambda theta: theta*theta*(1-theta)*theta*(1-theta)*(theta**alpha)*(1-theta)**beta\n",
        "\n",
        "theta_vals = np.linspace(0,1)\n",
        "plt.plot(theta_vals, coin_likelihood(theta_vals))"
      ],
      "metadata": {
        "id": "q4CP7M3wE7X_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}